# Data Engineering & Machine Learning

![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![Jupyter](https://img.shields.io/badge/Jupyter-Notebook-orange)
![NumPy](https://img.shields.io/badge/NumPy-1.21%2B-blue)
![Pandas](https://img.shields.io/badge/Pandas-1.3%2B-lightblue)
![Scikit-learn](https://img.shields.io/badge/Scikit--learn-0.24%2B-yellowgreen)
![Matplotlib](https://img.shields.io/badge/Matplotlib-3.4%2B-blue)
![GitHub](https://img.shields.io/badge/GitHub-Repository-black)

This repository contains a collection of **Jupyter notebooks** developed as part of the Data Engineering & Machine Learning module. The aim is to provide foundational knowledge in information and data engineering, along with key machine learning concepts. Python is the main programming language used to enhance both mathematical and coding skills, while exploring advanced topics like modern machine learning platforms, data visualization, and deep learning.

# Index

- [Data Engineering & Machine Learning](#data-engineering--machine-learning)
- [Index](#index)
  - [ðŸ“Œ Main Topics](#-main-topics)
  - [ðŸ“˜ Activities](#-activities)
    - [1. Linear Algebra & Python](#1-linear-algebra--python)
    - [2. Probability & Python](#2-probability--python)
    - [3. Artificial Neurons](#3-artificial-neurons)
    - [4. Logistics Regression and SVMs](#4-logistics-regression-and-svms)
    - [5. Data Processing](#5-data-processing)
    - [6. Neural Networks](#6-neural-networks)
  - [ðŸ‘¥ Contribution](#-contribution)

## ðŸ“Œ Main Topics

The following aspects of machine learning are covered:

1. **Machine Learning Algorithms**: Introduction to fundamental techniques like Perceptron, Logistic Regression, Support Vector Machines, and Multi-Layer Perceptron, using libraries like *Scikit-learn*.

2. **Data Processing and Visualization**: Applying techniques for data pre-processing, post-processing, and visualization using libraries like *NumPy*, *Pandas*, and *Matplotlib*.

3. **Practical Applications**: Using real-world datasets to identify trends, make inferences, and implement solutions for tasks such as image classification.

## ðŸ“˜ Activities

### 1. Linear Algebra & Python

The purpose of this activity is to become confident with *matrix addition*, *subtraction*, *multiplication*, *determining matrix determinants*, *inverse*, *cross-product* and *eigenvalues*, developing code for these operations and creating Python functions to represent this functionality in a reusable way.

The first Jupyter Notebook could be found here: [Activity 1](https://github.com/Arianna6400/DE-ML/blob/master/Activity1/Etivity1_LinearAlgebra.ipynb).

### 2. Probability & Python

This activity focuses on the application of *probability theory*, utilizing Python's *Random* module to simulate random events and generate datasets. Statistical properties of these datasets are calculated and compared to theoretical estimates to assess the alignment between simulated and expected outcomes. Additionally, data distributions are visualized to gain deeper insights into the stochastic nature of the generated datasets.

This exploration is essential for understanding the probabilistic foundations of real-world machine learning problems, where data and algorithms often exhibit stochastic behavior.

The activity also extends Python programming skills by introducing topics such as reading CSV files and object-oriented programming through the use of classes. Furthermore, it serves as an introduction to **Reinforcement Learning**, complementing previous knowledge of supervised and unsupervised learning, thus broadening the understanding of different learning paradigms in machine learning. 

The second Jupyter Notebook could be found here: [Activity 2](https://github.com/Arianna6400/DE-ML/blob/master/Activity2/Etivity2_Probability.ipynb).

### 3. Artificial Neurons

Over the course of this activity, the focus is on exploring the fundamentals of artificial neurons, also known as **Perceptrons**, which are essential components of neural networks and deep learning. The activity covers the theory of perceptron learning and applies it to a dataset that can be linearly separated. In particular, an **Adaline** perceptron algorithm will be used, which is a perceptron that is trained with a gradient descent algorithm.

This first Jupyter Notebook could be found here: [Activity 3.1](https://github.com/Arianna6400/DE-ML/blob/master/Activity3/Etivity3_Adaline.ipynb)

Additionally, the implementation of a perceptron using gradient descent in scikit-learn is examined and compared with the Perceptron learning rule. The activity also involves working with datasets using the Pandas library and further exploring the scikit-learn library.

The second Jupyter Notebook could be found here: [Activity 3.2](https://github.com/Arianna6400/DE-ML/blob/master/Activity3/Etivity3_ScikitLearn.ipynb)

Through this task, foundational concepts of machine learning, such as weights, epochs, and learning rates, are introduced and explored, providing a solid base for understanding more advanced neural network models.

### 4. Logistics Regression and SVMs 

This notebook investigates the use of *Support Vector Machines* (**SVM**) in both classical and applied classification contexts, demonstrating SVMâ€™s versatility across three sections.

- **Part 1: Linear SVM on the Iris Dataset**
The first section applies a linear SVM model to classify the three species in the **Iris dataset** (*Iris-setosa*, *Iris-versicolor*, and *Iris-virginica*) based on petal length and width features. Data preprocessing includes scaling and splitting into training and test sets to optimize the model's performance. The linear SVM model is trained, and its accuracy is evaluated using a confusion matrix and classification report. The decision boundary is visualized to illustrate the linear modelâ€™s effectiveness in separating the classes.

- **Part 2: Non-Linear SVM on a Randomly Generated Dataset**
The second section demonstrates a non-linear SVM with a *radial basis function* (**RBF**) kernel on a randomly generated dataset. This section investigates how the non-linear SVM model captures complex, non-linear boundaries, showcasing its adaptability to data that is not linearly separable. The decision boundaries for this synthetic data are visualized to highlight the differences between linear and non-linear classification approaches.

- **Part 3: Network Intrusion Detection with SVM**
The final section explores SVMâ€™s application in **Network Intrusion Detection**, classifying network traffic as either normal or malicious. Using an intrusion detection dataset, the data is preprocessed and scaled, and both linear and non-linear SVM models are trained. Performance is assessed with metrics tailored for imbalanced data, providing insights into the SVMâ€™s effectiveness in identifying intrusions and demonstrating its relevance in cybersecurity.

The Jupyter Notebook could be found here: [Activity 4](https://github.com/Arianna6400/DE-ML/blob/master/Activity4/Etivity4_SVM.ipynb)

### 5. Data Processing

*TO BE CONTINUED..*

### 6. Neural Networks

*TO BE CONTINUED..*

## ðŸ‘¥ Contribution

|Nome | GitHub |
|-----------|--------|
| ðŸ‘© `Agresta Arianna` | [Click here](https://github.com/Arianna6400) |

